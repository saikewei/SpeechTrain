<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue'
import { useRouter } from 'vue-router'
import type { Course, CourseContent, AnalysisResult } from '../../../shared/types'

const router = useRouter()

// çŠ¶æ€å®šä¹‰
type State = 'idle' | 'recording' | 'analyzing' | 'result'
const currentState = ref<State>('idle')

const isLoading = ref(true)
const course = ref<Course | undefined>(undefined)
const currentSentence = ref<CourseContent | undefined>(undefined)
const currentIndex = ref(0)
const currentPhonemes = ref<string>('')

// æ’­æ”¾ç¤ºä¾‹è¯­éŸ³ç›¸å…³
const isPlayingExample = ref(false)
const isTTSConfigured = ref(false)
let exampleAudioContext: AudioContext | null = null

onMounted(async () => {
  try {
    isLoading.value = true
    const courseId = router.currentRoute.value.params.id as string
    // è°ƒç”¨ preload ä¸­æš´éœ²çš„ API è·å–è¯¾ç¨‹è¯¦æƒ…
    course.value = await window.api.getCourseDetail(courseId)
    window.api.setEspeakLanguage(course.value?.lang || 'en')
    currentPhonemes.value = await window.api.phonemize(course.value?.content[0].text || '')
    console.log('Phonemes:', currentPhonemes.value)
    if (!course.value) {
      console.error('Course not found:', courseId)
      return
    }
    currentSentence.value = course.value.content[0]

    // æ£€æŸ¥ TTS æ˜¯å¦é…ç½®
    isTTSConfigured.value = await window.api.ttsIsConfigured()
  } catch (error) {
    console.error('Failed to load practice data:', error)
  } finally {
    isLoading.value = false
  }
})

onUnmounted(() => {
  if (currentState.value === 'recording') {
    stopRecording()
  }
  if (playbackAudioContext) {
    stopPlayback()
  }
  if (exampleAudioContext) {
    stopExamplePlayback()
  }
})

// æ’­æ”¾ç¤ºä¾‹è¯­éŸ³
const playExampleAudio = async (): Promise<void> => {
  if (!currentSentence.value || isPlayingExample.value || !isTTSConfigured.value) return

  try {
    isPlayingExample.value = true

    // è°ƒç”¨ TTS API
    const audioData = (await window.api.ttsSynthesize(
      currentSentence.value.text,
      course.value?.lang || 'en'
    )) as ArrayBuffer | Uint8Array | number[]

    // ç¡®ä¿æ•°æ®æ˜¯ ArrayBuffer ç±»å‹
    let audioBuffer: ArrayBuffer
    if (audioData instanceof ArrayBuffer) {
      audioBuffer = audioData
    } else if (audioData instanceof Uint8Array) {
      audioBuffer = audioData.buffer as ArrayBuffer
    } else if (Array.isArray(audioData)) {
      audioBuffer = new Uint8Array(audioData).buffer
    } else {
      throw new Error('ä¸æ”¯æŒçš„éŸ³é¢‘æ•°æ®æ ¼å¼')
    }

    // åˆ›å»º AudioContext æ’­æ”¾
    exampleAudioContext = new AudioContext()
    const decodedData = await exampleAudioContext.decodeAudioData(audioBuffer)

    const source = exampleAudioContext.createBufferSource()
    source.buffer = decodedData
    source.connect(exampleAudioContext.destination)

    source.onended = () => {
      isPlayingExample.value = false
      if (exampleAudioContext) {
        exampleAudioContext.close()
        exampleAudioContext = null
      }
    }

    source.start(0)
  } catch (error) {
    console.error('æ’­æ”¾ç¤ºä¾‹è¯­éŸ³å¤±è´¥:', error)
    alert('æ’­æ”¾å¤±è´¥: ' + (error as Error).message)
    isPlayingExample.value = false
    if (exampleAudioContext) {
      await exampleAudioContext.close()
      exampleAudioContext = null
    }
  }
}

const stopExamplePlayback = (): void => {
  if (exampleAudioContext) {
    exampleAudioContext.close()
    exampleAudioContext = null
  }
  isPlayingExample.value = false
}

// --- å½•éŸ³ç›¸å…³å˜é‡ ---
let audioContext: AudioContext | null = null
let mediaStream: MediaStream | null = null
let scriptProcessor: ScriptProcessorNode | null = null
let audioInput: MediaStreamAudioSourceNode | null = null
const recordedChunks: Float32Array[] = [] // æš‚å­˜å½•éŸ³ç‰‡æ®µ
let recordedAudioData: Float32Array | null = null // ä¿å­˜å®Œæ•´å½•éŸ³æ•°æ®

// å¼€å§‹å½•éŸ³
const startRecording = async (): Promise<void> => {
  if (isPlayingExample.value) {
    stopExamplePlayback()
  }
  try {
    // 1. è·å–éº¦å…‹é£æƒé™
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })
    // 2. åˆ›å»º AudioContext
    audioContext = new window.AudioContext({ sampleRate: 16000 })
    // 3. åˆ›å»ºæºèŠ‚ç‚¹
    audioInput = audioContext.createMediaStreamSource(mediaStream)
    // 4. åˆ›å»ºå¤„ç†èŠ‚ç‚¹ (ç¼“å†²åŒºå¤§å° 4096)
    // ScriptProcessorNode è™½ç„¶è¢«æ ‡è®°ä¸ºåºŸå¼ƒï¼Œä½†åœ¨ Electron ç¯å¢ƒä¸‹ä¾ç„¶ç¨³å®šä¸”ç®€å•
    scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1)
    // 5. ç›‘å¬éŸ³é¢‘å¤„ç†äº‹ä»¶
    scriptProcessor.onaudioprocess = (event) => {
      if (currentState.value !== 'recording') return
      const inputBuffer = event.inputBuffer
      const inputData = inputBuffer.getChannelData(0) // è·å–å•å£°é“æ•°æ®
      // å¤åˆ¶ä¸€ä»½æ•°æ®å­˜èµ·æ¥ (Float32Array)
      recordedChunks.push(new Float32Array(inputData))
    }
    // 6. è¿æ¥èŠ‚ç‚¹: Source -> Processor -> Destination
    audioInput.connect(scriptProcessor)
    scriptProcessor.connect(audioContext.destination)
    // æ¸…ç©ºæ—§æ•°æ®
    recordedChunks.length = 0
    currentState.value = 'recording'
  } catch (err) {
    console.error('æ— æ³•å¯åŠ¨å½•éŸ³:', err)
    alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®ã€‚')
  }
}

// åœæ­¢å½•éŸ³å¹¶åˆå¹¶æ•°æ®
const stopRecording = async (): Promise<void> => {
  if (currentState.value !== 'recording') return
  // 1. åœæ­¢å¤„ç†
  if (scriptProcessor) {
    scriptProcessor.disconnect()
    scriptProcessor = null
  }
  if (audioInput) {
    audioInput.disconnect()
    audioInput = null
  }
  if (mediaStream) {
    mediaStream.getTracks().forEach((track) => track.stop())
    mediaStream = null
  }
  if (audioContext) {
    await audioContext.close()
    audioContext = null
  }
  currentState.value = 'analyzing'
  // 2. åˆå¹¶æ‰€æœ‰ç‰‡æ®µä¸ºä¸€ä¸ªå¤§çš„ Float32Array
  const totalLength = recordedChunks.reduce((acc, chunk) => acc + chunk.length, 0)
  const fullAudioData = new Float32Array(totalLength)
  let offset = 0
  for (const chunk of recordedChunks) {
    fullAudioData.set(chunk, offset)
    offset += chunk.length
  }

  // ä¿å­˜å½•éŸ³æ•°æ®ç”¨äºæ’­æ”¾
  recordedAudioData = fullAudioData

  console.log('å½•éŸ³æ•°æ®é•¿åº¦:', fullAudioData.length)
  console.log(fullAudioData)
  // 3. å‘é€ç»™åç«¯åˆ†æ
  analyzeAudio(fullAudioData)
}

const result = ref<AnalysisResult | null>(null)

// è°ƒç”¨åç«¯ API
const analyzeAudio = async (pcmData: Float32Array): Promise<void> => {
  try {
    if (!currentSentence.value) return

    result.value = await window.api.analyzeRawAudio(pcmData, currentSentence.value.text)
    currentState.value = 'result'
    // å°† Float32Array è½¬æ¢ä¸ºæ™®é€šæ•°ç»„ä¼ é€’ç»™åç«¯
    const pcmArray = Array.from(pcmData)
    const llm_result = await window.api.llmAnalyzeAudio(
      pcmArray,
      `è¿™æ˜¯ä¸€ä¸ªå£è¯­ç»ƒä¹ è€…çš„å½•éŸ³ï¼ŒåŸæ–‡æ˜¯"${currentSentence.value.text}"ï¼Œè¯·å®¢è§‚è¯„ä»·ä»–çš„å‘éŸ³è´¨é‡ã€‚å¦‚æœå‘éŸ³ä¸å¥½ï¼Œè¯·æŒ‡å‡ºå…·ä½“çš„é”™è¯¯ä¹‹å¤„ï¼Œå¹¶ç»™å‡ºæ”¹è¿›å»ºè®®ã€‚`
    )
    console.log('LLM åˆ†æç»“æœ:', llm_result)

    console.log('åˆ†æç»“æœ:', result.value)
  } catch (error) {
    console.error('åˆ†æå¤±è´¥:', error)
    alert('åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•')
    currentState.value = 'idle'
  }
}

const toggleRecord = (): void => {
  if (currentState.value === 'idle') {
    startRecording()
  } else if (currentState.value === 'recording') {
    stopRecording()
  }
}

const nextSentence = (): void => {
  if (!course.value) return
  currentIndex.value += 1
  if (currentIndex.value >= course.value.content.length) {
    // è¯¾ç¨‹ç»“æŸï¼Œè¿”å›é¦–é¡µ
    router.push('/')
    return
  }
  currentSentence.value = course.value.content[currentIndex.value]
  currentPhonemes.value = ''
  window.api.phonemize(currentSentence.value.text).then((phonemes) => {
    currentPhonemes.value = phonemes
  })
  currentState.value = 'idle'
  recordedChunks.length = 0
  result.value = null
  recordedAudioData = null
  isPlayingRecording.value = false
}

const retry = (): void => {
  currentState.value = 'idle'
  recordedChunks.length = 0
  result.value = null
  recordedAudioData = null
  isPlayingRecording.value = false
}

// è®¡ç®—æŒ‡æ•°åŒ–åçš„å¾—åˆ†
const getDisplayScore = (score: number): number => {
  return Math.round(Math.exp(score) * 100)
}

// æ ¹æ®å¾—åˆ†è·å–é¢œè‰²ç­‰çº§
const getScoreLevel = (score: number): 'good' | 'medium' | 'bad' => {
  const displayScore = getDisplayScore(score)
  if (displayScore >= 70) return 'good'
  if (displayScore >= 40) return 'medium'
  return 'bad'
}

// æ’­æ”¾å½•éŸ³ç›¸å…³
const isPlayingRecording = ref(false)
let playbackAudioContext: AudioContext | null = null

const playRecording = async (): Promise<void> => {
  if (!recordedAudioData || isPlayingRecording.value) return

  try {
    isPlayingRecording.value = true

    // åˆ›å»ºæ–°çš„ AudioContext ç”¨äºæ’­æ”¾
    playbackAudioContext = new AudioContext({ sampleRate: 16000 })

    // åˆ›å»º AudioBuffer
    const audioBuffer = playbackAudioContext.createBuffer(
      1, // å•å£°é“
      recordedAudioData.length,
      16000 // é‡‡æ ·ç‡
    )

    // å°†å½•éŸ³æ•°æ®å¤åˆ¶åˆ° AudioBuffer
    audioBuffer.copyToChannel(recordedAudioData as Float32Array<ArrayBuffer>, 0)

    // åˆ›å»º BufferSource å¹¶æ’­æ”¾
    const source = playbackAudioContext.createBufferSource()
    source.buffer = audioBuffer
    source.connect(playbackAudioContext.destination)

    // æ’­æ”¾ç»“æŸåé‡ç½®çŠ¶æ€
    source.onended = () => {
      isPlayingRecording.value = false
      if (playbackAudioContext) {
        playbackAudioContext.close()
        playbackAudioContext = null
      }
    }

    source.start(0)
  } catch (error) {
    console.error('æ’­æ”¾å½•éŸ³å¤±è´¥:', error)
    isPlayingRecording.value = false
    if (playbackAudioContext) {
      await playbackAudioContext.close()
      playbackAudioContext = null
    }
  }
}

const stopPlayback = (): void => {
  if (playbackAudioContext) {
    playbackAudioContext.close()
    playbackAudioContext = null
  }
  isPlayingRecording.value = false
}
</script>

<template>
  <div class="practice-page">
    <!-- é¡¶éƒ¨å¯¼èˆª -->
    <div class="top-bar">
      <button class="back-btn" @click="router.back()">â† é€€å‡º</button>
      <div class="progress">Lesson 1: {{ currentIndex + 1 }}/{{ course?.content.length }}</div>
    </div>

    <!-- ä¸»è¦å†…å®¹åŒº -->
    <div class="content-area">
      <!-- 1. å¥å­å±•ç¤ºåŒº -->
      <div class="sentence-card">
        <!-- ç»“æœæ¨¡å¼ä¸‹ï¼šæ˜¾ç¤ºå½©è‰²å•è¯å’ŒéŸ³ç´  -->
        <div v-if="currentState === 'result'" class="result-text">
          <div v-for="(wordData, idx) in result?.words" :key="idx" class="word-container">
            <div class="word" :class="getScoreLevel(wordData.score)">
              <span class="word-text">{{ wordData.word }}</span>
              <div class="word-score">{{ getDisplayScore(wordData.score) }}</div>
            </div>
            <div class="phonemes">
              <span
                v-for="(phoneme, pIdx) in wordData.phonemes"
                :key="pIdx"
                class="phoneme"
                :class="getScoreLevel(phoneme.score)"
                :title="`å¾—åˆ†: ${getDisplayScore(phoneme.score)}`"
              >
                {{ phoneme.ipa }}
              </span>
            </div>
          </div>
        </div>

        <!-- æ™®é€šæ¨¡å¼ä¸‹ï¼šæ˜¾ç¤ºçº¯æ–‡æœ¬ -->
        <div v-else>
          <h2 class="main-text">{{ currentSentence?.text }}</h2>
          <div class="phonetic">{{ currentPhonemes }}</div>
        </div>

        <button
          v-if="currentState !== 'result' && isTTSConfigured"
          class="example-audio-btn"
          :disabled="isPlayingExample"
          @click="playExampleAudio"
        >
          {{ isPlayingExample ? 'ğŸ”Š æ’­æ”¾ä¸­...' : 'ğŸ”Š å¬ç¤ºä¾‹' }}
        </button>

        <div v-if="!isTTSConfigured && currentState !== 'result'" class="tts-warning">
          âš ï¸ TTS æœªé…ç½®ï¼Œæ— æ³•æ’­æ”¾ç¤ºä¾‹è¯­éŸ³
        </div>
      </div>

      <!-- 2. è¯„åˆ†åé¦ˆåœ†ç¯ (ä»…åœ¨ç»“æœé¡µæ˜¾ç¤º) -->
      <div
        v-if="currentState === 'result'"
        class="score-circle"
        :class="result ? getScoreLevel(result.overall_score) : ''"
      >
        <div class="score-number">{{ result ? getDisplayScore(result.overall_score) : 'N/A' }}</div>
        <div class="score-label">æ€»åˆ†</div>
      </div>

      <!-- 3. çŠ¶æ€æç¤º -->
      <div class="status-text">
        <span v-if="currentState === 'idle'">ç‚¹å‡»éº¦å…‹é£å¼€å§‹è·Ÿè¯»</span>
        <span v-if="currentState === 'recording'" class="recording-dot"
          >ğŸ”´ æ­£åœ¨å½•éŸ³... (ç‚¹å‡»åœæ­¢)</span
        >
        <span v-if="currentState === 'analyzing'">ğŸ¤– AI æ­£åœ¨åˆ†ææ‚¨çš„å‘éŸ³...</span>
      </div>
    </div>

    <!-- åº•éƒ¨æ“ä½œåŒº -->
    <div class="action-bar">
      <button
        v-if="currentState !== 'result'"
        class="mic-btn"
        :class="{ recording: currentState === 'recording', disabled: currentState === 'analyzing' }"
        :disabled="currentState === 'analyzing'"
        @click="toggleRecord"
      >
        <span class="mic-icon">ğŸ™ï¸</span>
      </button>
      <div v-else class="result-actions">
        <button class="play-btn" :disabled="isPlayingRecording" @click="playRecording">
          {{ isPlayingRecording ? 'â¸ï¸ æ’­æ”¾ä¸­...' : 'â–¶ï¸ æ’­æ”¾å½•éŸ³' }}
        </button>
        <button class="retry-btn" @click="retry">å†æ¥ä¸€æ¬¡</button>
        <button class="next-btn" @click="nextSentence">ä¸‹ä¸€å¥ â†’</button>
      </div>
    </div>
  </div>
</template>

<style scoped>
.practice-page {
  height: 100vh;
  display: flex;
  flex-direction: column;
  background: #f8f9fa;
  user-select: none;
}

.main-text {
  user-select: text;
}

.top-bar {
  padding: 15px 20px;
  display: flex;
  justify-content: space-between;
  align-items: center;
  color: #666;
}
.back-btn {
  border: none;
  background: none;
  cursor: pointer;
  font-size: 1rem;
  color: #666;
}

.content-area {
  flex: 1;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  padding: 20px;
  text-align: center;
}

.sentence-card h2 {
  font-size: 2rem;
  color: #2c3e50;
  margin-bottom: 10px;
}
.phonetic {
  color: #7f8c8d;
  font-family: monospace;
  font-size: 1.2rem;
}

/* ç»“æœå•è¯æ ·å¼ */
.result-text {
  font-size: 1.5rem;
  font-weight: bold;
  display: flex;
  flex-wrap: wrap;
  gap: 20px;
  justify-content: center;
  align-items: flex-start;
}

.word-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 8px;
}

.word {
  position: relative;
  cursor: default;
  padding: 8px 12px;
  border-radius: 8px;
  background: #f0f0f0;
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 4px;
}

.word.good {
  background: #d4edda;
  border: 2px solid #28a745;
}

.word.medium {
  background: #fff3cd;
  border: 2px solid #ffc107;
}

.word.bad {
  background: #f8d7da;
  border: 2px solid #dc3545;
}

.word-text {
  font-size: 1.5rem;
}

.word-score {
  font-size: 0.9rem;
  color: #666;
  font-weight: normal;
}

.phonemes {
  display: flex;
  gap: 4px;
  flex-wrap: wrap;
  justify-content: center;
}

.phoneme {
  padding: 4px 8px;
  border-radius: 4px;
  font-size: 0.85rem;
  font-family: monospace;
  background: #f0f0f0;
  cursor: help;
  transition: transform 0.2s;
}

.phoneme:hover {
  transform: scale(1.1);
}

.phoneme.good {
  background: #c3e6cb;
  color: #155724;
}

.phoneme.medium {
  background: #fff3cd;
  color: #856404;
}

.phoneme.bad {
  background: #f5c6cb;
  color: #721c24;
}

/* ç®€å•çš„ Tooltip */
.score-tooltip {
  visibility: hidden;
  position: absolute;
  bottom: 100%;
  left: 50%;
  transform: translateX(-50%);
  background: #333;
  color: white;
  font-size: 0.8rem;
  padding: 4px 8px;
  border-radius: 4px;
  opacity: 0;
  transition: opacity 0.2s;
}
.word:hover .score-tooltip {
  visibility: visible;
  opacity: 1;
}

/* è¯„åˆ†åœ†ç¯ */
.score-circle {
  margin: 30px 0;
  width: 100px;
  height: 100px;
  border-radius: 50%;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  background: white;
  transition: all 0.3s;
}

.score-circle.good {
  border: 5px solid #28a745;
  box-shadow: 0 4px 15px rgba(40, 167, 69, 0.3);
}

.score-circle.good .score-number {
  color: #28a745;
}

.score-circle.medium {
  border: 5px solid #ffc107;
  box-shadow: 0 4px 15px rgba(255, 193, 7, 0.3);
}

.score-circle.medium .score-number {
  color: #ffc107;
}

.score-circle.bad {
  border: 5px solid #dc3545;
  box-shadow: 0 4px 15px rgba(220, 53, 69, 0.3);
}

.score-circle.bad .score-number {
  color: #dc3545;
}

.score-number {
  font-size: 2.5rem;
  font-weight: bold;
}
.score-label {
  font-size: 0.8rem;
  color: #666;
}

.status-text {
  margin-top: 20px;
  height: 24px;
  color: #666;
}
.recording-dot {
  color: #e74c3c;
  animation: pulse 1.5s infinite;
}

/* åº•éƒ¨æ“ä½œæ  */
.action-bar {
  padding: 40px;
  display: flex;
  justify-content: center;
  background: white;
  border-top: 1px solid #eee;
}

.mic-btn {
  width: 80px;
  height: 80px;
  border-radius: 50%;
  border: none;
  background: #42b883;
  color: white;
  font-size: 2rem;
  cursor: pointer;
  box-shadow: 0 4px 15px rgba(66, 184, 131, 0.4);
  transition: all 0.3s;
}
.mic-btn:hover {
  transform: scale(1.05);
}
.mic-btn.recording {
  background: #e74c3c;
  box-shadow: 0 0 0 10px rgba(231, 76, 60, 0.2);
}
.mic-btn.disabled {
  background: #ccc;
  cursor: not-allowed;
  box-shadow: none;
}

.result-actions {
  display: flex;
  gap: 15px;
  align-items: center;
}

.play-btn {
  padding: 15px 30px;
  background: #3498db;
  color: white;
  border: none;
  border-radius: 30px;
  font-size: 1.1rem;
  cursor: pointer;
  transition: background 0.2s;
}

.play-btn:hover:not(:disabled) {
  background: #2980b9;
}

.play-btn:disabled {
  background: #95a5a6;
  cursor: not-allowed;
}

.next-btn {
  padding: 15px 40px;
  background: #2c3e50;
  color: white;
  border: none;
  border-radius: 30px;
  font-size: 1.2rem;
  cursor: pointer;
  transition: background 0.2s;
}

.next-btn:hover {
  background: #34495e;
}

.retry-btn {
  padding: 15px 40px;
  background: #7f8c8d;
  color: white;
  border: none;
  border-radius: 30px;
  font-size: 1.2rem;
  cursor: pointer;
  transition: background 0.2s;
}

.retry-btn:hover {
  background: #95a5a6;
}

.example-audio-btn {
  margin-top: 15px;
  padding: 10px 25px;
  background: #3498db;
  color: white;
  border: none;
  border-radius: 20px;
  font-size: 1rem;
  cursor: pointer;
  transition: all 0.2s;
}

.example-audio-btn:hover:not(:disabled) {
  background: #2980b9;
  transform: translateY(-2px);
}

.example-audio-btn:disabled {
  background: #95a5a6;
  cursor: not-allowed;
}

.tts-warning {
  margin-top: 10px;
  font-size: 0.9rem;
  color: #e67e22;
}

@keyframes pulse {
  0% {
    opacity: 1;
  }
  50% {
    opacity: 0.5;
  }
  100% {
    opacity: 1;
  }
}
</style>
