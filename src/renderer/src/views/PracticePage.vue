<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue'
import { useRouter } from 'vue-router'
import type { Course, CourseContent, AnalysisResult } from '../../../shared/types'

const router = useRouter()

// çŠ¶æ€å®šä¹‰
type State = 'idle' | 'recording' | 'analyzing' | 'result'
const currentState = ref<State>('idle')

const isLoading = ref(true)
const course = ref<Course | undefined>(undefined)
const currentSentence = ref<CourseContent | undefined>(undefined)
const currentIndex = ref(0)
const currentPhonemes = ref<string>('')

onMounted(async () => {
  try {
    isLoading.value = true
    const courseId = router.currentRoute.value.params.id as string
    // è°ƒç”¨ preload ä¸­æš´éœ²çš„ API è·å–è¯¾ç¨‹è¯¦æƒ…
    course.value = await window.api.getCourseDetail(courseId)
    window.api.setEspeakLanguage(course.value?.lang || 'en')
    currentPhonemes.value = await window.api.phonemize(course.value?.content[0].text || '')
    console.log('Phonemes:', currentPhonemes.value)
    if (!course.value) {
      console.error('Course not found:', courseId)
      return
    }
    currentSentence.value = course.value.content[0]
  } catch (error) {
    console.error('Failed to load practice data:', error)
  } finally {
    isLoading.value = false
  }
})

onUnmounted(() => {
  if (currentState.value === 'recording') {
    stopRecording()
  }
})

// --- å½•éŸ³ç›¸å…³å˜é‡ ---
let audioContext: AudioContext | null = null
let mediaStream: MediaStream | null = null
let scriptProcessor: ScriptProcessorNode | null = null
let audioInput: MediaStreamAudioSourceNode | null = null
const recordedChunks: Float32Array[] = [] // æš‚å­˜å½•éŸ³ç‰‡æ®µ

// å¼€å§‹å½•éŸ³
const startRecording = async (): Promise<void> => {
  try {
    // 1. è·å–éº¦å…‹é£æƒé™
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true })
    // 2. åˆ›å»º AudioContext
    audioContext = new window.AudioContext({ sampleRate: 16000 })
    // 3. åˆ›å»ºæºèŠ‚ç‚¹
    audioInput = audioContext.createMediaStreamSource(mediaStream)
    // 4. åˆ›å»ºå¤„ç†èŠ‚ç‚¹ (ç¼“å†²åŒºå¤§å° 4096)
    // ScriptProcessorNode è™½ç„¶è¢«æ ‡è®°ä¸ºåºŸå¼ƒï¼Œä½†åœ¨ Electron ç¯å¢ƒä¸‹ä¾ç„¶ç¨³å®šä¸”ç®€å•
    scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1)
    // 5. ç›‘å¬éŸ³é¢‘å¤„ç†äº‹ä»¶
    scriptProcessor.onaudioprocess = (event) => {
      if (currentState.value !== 'recording') return
      const inputBuffer = event.inputBuffer
      const inputData = inputBuffer.getChannelData(0) // è·å–å•å£°é“æ•°æ®
      // å¤åˆ¶ä¸€ä»½æ•°æ®å­˜èµ·æ¥ (Float32Array)
      recordedChunks.push(new Float32Array(inputData))
    }
    // 6. è¿æ¥èŠ‚ç‚¹: Source -> Processor -> Destination
    audioInput.connect(scriptProcessor)
    scriptProcessor.connect(audioContext.destination)
    // æ¸…ç©ºæ—§æ•°æ®
    recordedChunks.length = 0
    currentState.value = 'recording'
  } catch (err) {
    console.error('æ— æ³•å¯åŠ¨å½•éŸ³:', err)
    alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®ã€‚')
  }
}

// åœæ­¢å½•éŸ³å¹¶åˆå¹¶æ•°æ®
const stopRecording = async (): Promise<void> => {
  if (currentState.value !== 'recording') return
  // 1. åœæ­¢å¤„ç†
  if (scriptProcessor) {
    scriptProcessor.disconnect()
    scriptProcessor = null
  }
  if (audioInput) {
    audioInput.disconnect()
    audioInput = null
  }
  if (mediaStream) {
    mediaStream.getTracks().forEach((track) => track.stop())
    mediaStream = null
  }
  if (audioContext) {
    await audioContext.close()
    audioContext = null
  }
  currentState.value = 'analyzing'
  // 2. åˆå¹¶æ‰€æœ‰ç‰‡æ®µä¸ºä¸€ä¸ªå¤§çš„ Float32Array
  const totalLength = recordedChunks.reduce((acc, chunk) => acc + chunk.length, 0)
  const fullAudioData = new Float32Array(totalLength)
  let offset = 0
  for (const chunk of recordedChunks) {
    fullAudioData.set(chunk, offset)
    offset += chunk.length
  }

  console.log('å½•éŸ³æ•°æ®é•¿åº¦:', fullAudioData.length)
  console.log(fullAudioData)
  // 3. å‘é€ç»™åç«¯åˆ†æ
  analyzeAudio(fullAudioData)
}

const result = ref<AnalysisResult | null>(null)

// è°ƒç”¨åç«¯ API
const analyzeAudio = async (pcmData: Float32Array): Promise<void> => {
  try {
    if (!currentSentence.value) return

    result.value = await window.api.analyzeRawAudio(pcmData, currentSentence.value.text)
    currentState.value = 'result'

    console.log('åˆ†æç»“æœ:', result.value)
  } catch (error) {
    console.error('åˆ†æå¤±è´¥:', error)
    alert('åˆ†æå¤±è´¥ï¼Œè¯·é‡è¯•')
    currentState.value = 'idle'
  }
}

const toggleRecord = (): void => {
  if (currentState.value === 'idle') {
    startRecording()
  } else if (currentState.value === 'recording') {
    stopRecording()
  }
}

const nextSentence = (): void => {
  if (!course.value) return
  currentIndex.value += 1
  if (currentIndex.value >= course.value.content.length) {
    // è¯¾ç¨‹ç»“æŸï¼Œè¿”å›é¦–é¡µ
    router.push('/')
    return
  }
  currentSentence.value = course.value.content[currentIndex.value]
  currentState.value = 'idle'
  recordedChunks.length = 0
  result.value = null
}
</script>

<template>
  <div class="practice-page">
    <!-- é¡¶éƒ¨å¯¼èˆª -->
    <div class="top-bar">
      <button class="back-btn" @click="router.back()">â† é€€å‡º</button>
      <div class="progress">Lesson 1: {{ currentIndex + 1 }}/{{ course?.content.length }}</div>
    </div>

    <!-- ä¸»è¦å†…å®¹åŒº -->
    <div class="content-area">
      <!-- 1. å¥å­å±•ç¤ºåŒº -->
      <div class="sentence-card">
        <!-- ç»“æœæ¨¡å¼ä¸‹ï¼šæ˜¾ç¤ºå½©è‰²å•è¯ -->
        <div v-if="currentState === 'result'" class="result-text"></div>

        <!-- æ™®é€šæ¨¡å¼ä¸‹ï¼šæ˜¾ç¤ºçº¯æ–‡æœ¬ -->
        <div v-else>
          <h2 class="main-text">{{ currentSentence?.text }}</h2>
          <div class="phonetic">{{ currentPhonemes }}</div>
        </div>
      </div>

      <!-- 2. è¯„åˆ†åé¦ˆåœ†ç¯ (ä»…åœ¨ç»“æœé¡µæ˜¾ç¤º) -->
      <div v-if="currentState === 'result'" class="score-circle">
        <div class="score-number">{{ result ? result.overall_score : '' }}</div>
        <div class="score-label">æ€»åˆ†</div>
      </div>

      <!-- 3. çŠ¶æ€æç¤º -->
      <div class="status-text">
        <span v-if="currentState === 'idle'">ç‚¹å‡»éº¦å…‹é£å¼€å§‹è·Ÿè¯»</span>
        <span v-if="currentState === 'recording'" class="recording-dot"
          >ğŸ”´ æ­£åœ¨å½•éŸ³... (ç‚¹å‡»åœæ­¢)</span
        >
        <span v-if="currentState === 'analyzing'">ğŸ¤– AI æ­£åœ¨åˆ†ææ‚¨çš„å‘éŸ³...</span>
      </div>
    </div>

    <!-- åº•éƒ¨æ“ä½œåŒº -->
    <div class="action-bar">
      <button
        v-if="currentState !== 'result'"
        class="mic-btn"
        :class="{ recording: currentState === 'recording', disabled: currentState === 'analyzing' }"
        :disabled="currentState === 'analyzing'"
        @click="toggleRecord"
      >
        <span class="mic-icon">ğŸ™ï¸</span>
      </button>

      <button v-else class="next-btn" @click="nextSentence">ä¸‹ä¸€å¥ â†’</button>
    </div>
  </div>
</template>

<style scoped>
.practice-page {
  height: 100vh;
  display: flex;
  flex-direction: column;
  background: #f8f9fa;
  user-select: none;
}

.main-text {
  user-select: text;
}

.top-bar {
  padding: 15px 20px;
  display: flex;
  justify-content: space-between;
  align-items: center;
  color: #666;
}
.back-btn {
  border: none;
  background: none;
  cursor: pointer;
  font-size: 1rem;
  color: #666;
}

.content-area {
  flex: 1;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  padding: 20px;
  text-align: center;
}

.sentence-card h2 {
  font-size: 2rem;
  color: #2c3e50;
  margin-bottom: 10px;
}
.phonetic {
  color: #7f8c8d;
  font-family: monospace;
  font-size: 1.2rem;
}

/* ç»“æœå•è¯æ ·å¼ */
.result-text {
  font-size: 2rem;
  font-weight: bold;
  display: flex;
  flex-wrap: wrap;
  gap: 8px;
  justify-content: center;
}
.word {
  position: relative;
  cursor: default;
  padding: 0 2px;
  border-radius: 4px;
}
.word.good {
  color: #27ae60;
}
.word.bad {
  color: #e74c3c;
  text-decoration: underline;
  text-decoration-style: wavy;
}

/* ç®€å•çš„ Tooltip */
.score-tooltip {
  visibility: hidden;
  position: absolute;
  bottom: 100%;
  left: 50%;
  transform: translateX(-50%);
  background: #333;
  color: white;
  font-size: 0.8rem;
  padding: 4px 8px;
  border-radius: 4px;
  opacity: 0;
  transition: opacity 0.2s;
}
.word:hover .score-tooltip {
  visibility: visible;
  opacity: 1;
}

/* è¯„åˆ†åœ†ç¯ */
.score-circle {
  margin: 30px 0;
  width: 100px;
  height: 100px;
  border-radius: 50%;
  border: 5px solid #42b883;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  background: white;
  box-shadow: 0 4px 15px rgba(66, 184, 131, 0.2);
}
.score-number {
  font-size: 2.5rem;
  font-weight: bold;
  color: #42b883;
}
.score-label {
  font-size: 0.8rem;
  color: #666;
}

.status-text {
  margin-top: 20px;
  height: 24px;
  color: #666;
}
.recording-dot {
  color: #e74c3c;
  animation: pulse 1.5s infinite;
}

/* åº•éƒ¨æ“ä½œæ  */
.action-bar {
  padding: 40px;
  display: flex;
  justify-content: center;
  background: white;
  border-top: 1px solid #eee;
}

.mic-btn {
  width: 80px;
  height: 80px;
  border-radius: 50%;
  border: none;
  background: #42b883;
  color: white;
  font-size: 2rem;
  cursor: pointer;
  box-shadow: 0 4px 15px rgba(66, 184, 131, 0.4);
  transition: all 0.3s;
}
.mic-btn:hover {
  transform: scale(1.05);
}
.mic-btn.recording {
  background: #e74c3c;
  box-shadow: 0 0 0 10px rgba(231, 76, 60, 0.2);
}
.mic-btn.disabled {
  background: #ccc;
  cursor: not-allowed;
  box-shadow: none;
}

.next-btn {
  padding: 15px 40px;
  background: #2c3e50;
  color: white;
  border: none;
  border-radius: 30px;
  font-size: 1.2rem;
  cursor: pointer;
  transition: background 0.2s;
}
.next-btn:hover {
  background: #34495e;
}

@keyframes pulse {
  0% {
    opacity: 1;
  }
  50% {
    opacity: 0.5;
  }
  100% {
    opacity: 1;
  }
}
</style>
